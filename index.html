<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="utf-8"/>
  <title>Seiya Ito</title>
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.2/css/bootstrap.min.css" integrity="sha384-Smlep5jCw/wG7hdkwQ/Z5nLIefveQRIY9nfy6xoR1uRYBtpZgI6339F5dgvm/e9B" crossorigin="anonymous">
</head>
<body>
  <div class="container">
    <br>
    <div class="row">
      <div class="col-md-4 col-lg-4">
        <div class="text-center">
          <img id="me" alt="" src="imgs/alt.png" width="150" />
        </div>
      </div>
      <div class="col-md-8 col-lg-8">
          <br>
          <h4><b>Seiya Ito&nbsp; (伊東 聖矢)</b></h4>
          <br>
          <p>
            <b>Affiliation</b><br>
            Ph.D student at <a href="https://www.aoyama.ac.jp/">Aoyama Gakuin University</a>
          </p>
          <p>
            E-mail: ito.seiya[at]vss.it.aoyama.ac.jp<br>
            [<a href="https://www.linkedin.com/in/seiyaito/">LinkedIn</a>]
          </p>
      </div>
    </div>
    <br>

    <h4>News</h4>
    <ul>
      <li>One paper has been accepted to ACCV 2018 Workshop on Attention/Intention Understanding. "Human Action Recognition via Body Part Region Segmented Dense Trajectories".</li>
      <li>One paper has been accepted to ECCV 2018 Workshop on 3D Reconstruction in the Wild. "Deep Modular Network Architecture for Depth Estimation from Single Indoor Images".</li>
    </ul>

    <br>
    <h4>Education</h4>
    <table class="table">
      <tbody>
        <tr>
          <td width="20%">2018.4-Present</td>
          <td>
            Ph.D student, Aoyama Gakuin University<br>
            Graduate School of Science and Engineering
          </td>
        </tr>
        <tr>
          <td>2016.4-2018.3</td>
          <td>
              M.S., Aoyama Gakuin University<br>
              Graduate School of Science and Engineering
          </td>
        </tr>
        <tr>
          <td>2012.4-2016.3</td>
          <td>
            B.E., Aoyama Gakuin University<br>
            Department of Integrated Information Technology
          </td>
        </tr>
      </tbody>
    </table>
    <br>

    <h4>Research Experience</h4>
    <table class="table">
      <tbody>
        <tr>
          <td width="20%">2018.11-Present</td>
          <td>
            Research Assistant, Aoyama Gakuin University<br>
            Center for Advanced Information technology Research (CAIR)
          </td>
        </tr>
        <tr>
          <td>2017.02-2018.3</td>
          <td>
            Research Intern, Nippon Telegraph and Telephone Corporation<br>
            NTT Communication Science Laboratories
          </td>
        </tr>
      </tbody>
    </table>

    <h4>Research Interests</h4>
    <ul>
      <li>3D Reconstruction</li>
      <li>Depth Estimation</li>
      <li>Semantic Segmentation</li>
    </ul>

    <h4>Journal Publications</h4>
    <ol>
      <li>
        <p>
          Tomoya Kaneko, Junji Takahashi, <u>Seiya Ito</u>, Yoshito Tobe.<br>
          <b>A Hybrid Map with Permanent 3D Wireframes and Temporal Line Segments toward Long-term Visual Localization</b><br>
          SICE Journal of Control, Measurement, and System Integration (Special Issue on Fundamentals and Applications of Smart Sensing), 2019.
        </p>
      </li>

      <li>
        <p>
          金子 直史, <u>伊東 聖矢</u>, 鷲見 和彦.<br>
          <b>ClothesAwarePoseNet: 衣服の領域分割を考慮した人物姿勢推定法</b><br>
          電子情報通信学会論文誌 D (画像の認識・理解特集号), 2018 (in Japanese).<br>
          (<i style="color: #999">ClothesAwarePoseNet: Two-Stream Convolutional Networks for Clothing-Aware Human Pose Estimation)</i>
        </p>
      </li>

      <li>
        <p>
          <u>Seiya Ito</u>, Naoshi Kaneko, Takeshi Yoshida, and Kazuhiko Sumi.<br>
          <b>Detection of Defective Regions in 3D Reconstruction to Support Image Acquisition</b><br>
          SICE Journal of Control, Measurement, and System Integretion (Special Issue on Smart Sensing), 2017.
        </p>
      </li>
    </ol>
    <br>

    <h4>International Conference</h4>
    <ol>
      <li>
        <p>
          Kazunari Takagi, <u>Seiya Ito</u>, Naoshi Kaneko, Kazuhiko Sumi.<br>
          <b>Boosting Monocular Depth Estimation with Channel Attention and Mutual Learning</b><br>
          3rd International Conference on Imaging, Vision & Pattern Recognition (IVPR), 2019.
        </p>
      </li>

      <li>
        <p>
          Natsuki Hase, <u>Seiya Ito</u>, Naoshi Kaneko, Kazuhiko Sumi.<br>
          <b>Data Augmentation for Intra-Class Imbalance with Generative Adversarial Network</b><br>
          Quality Control by Artificial Vision (QCAV), 2019.
        </p>
      </li>

      <li>
        <p>
          Nobuhiro Suga, <u>Seiya Ito</u>, Naoshi Kaneko, Kazuhiko Sumi.<br>
          <b>Multiple Human Tracking with Dual Cost Graphs</b><br>
          Quality Control by Artificial Vision (QCAV), 2019.
        </p>
      </li>

      <li>
        <p>
          Masato Fukuzaki, <u>Seiya Ito</u>, Naoshi Kaneko, Kazuhiko Sumi.<br>
          <b>Robot Grasp Planning with Integration Map of Graspability and Object Occupancy</b><br>
          International Workshop on Frontiers of Computer Vision (IW-FCV), 2019.
        </p>
      </li>


      <li>
        <p>
          Kaho Yamada, <u>Seiya Ito</u>, Naoshi Kaneko, Kazuhiko Sumi.<br>
          <b>Human Action Recognition via Body Part Region Segmented Dense Trajectories</b><br>
          ACCV 2018 Workshop on Attention/Intention Understanding, 2018.
        </p>
      </li>

      <li>
        <p>
          <u>Seiya Ito</u>*, Naoshi Kaneko*, Yuma Shinohara, Kazuhiko Sumi (* equal contribution).<br>
          <b>Deep Modular Network Architecture for Depth Estimation from Single Indoor Images</b><br>
          ECCV 2018 Workshop on 3D Reconstruction in the Wild, 2018.
        </p>
      </li>

      <li>
        <p>
          <u>Seiya Ito</u>, Naoshi Kaneko, Junji Takahashi, and Kazuhiko Sumi.<br>
          <b>Global Localization from a Single Image in Known Indoor Environments</b><br>
          7th International Conference on Informatics, Electronics & Vision (ICIEV), 2018.
        </p>
      </li>
    </ol>
    <br>

    <h4>Domestic Conference</h4>
    <ul><li>12 papers</li></ul>
    <br>

    <h4>Awards</h4>
    <ul>
      <li>2019 Best Paper Award in IVPR2019.</li>
      <li>2019 Best poster presentation award in <a href="https://mr.hanyang.ac.kr/IW-FCV2019/conference/#award">IW-FCV2019</a>. </li>
      <li>2018 Best Master Thesis Award, Graduate School of Science and Engineering, Intelligence and Information Course, Aoyama Gakuin University. (3 winners out of 29 students)</li>
      <li>2016 Student Encouragement Award of 78th IPSJ National Convention.</li>
      <li>2016 Best Graduation Thesis Award, Department of Integrated Information Technology, Aoyama Gakuin University. (7 winners out of 120 students)</li>
    </ul>
    <br>

    <h4>Grants</h4>
    <ul>
      <li>2019 Early Eagle Program, Aoyama Gakuin University-Supported Program (PI)</li>
      <li>2018 Early Eagle Program, Aoyama Gakuin University-Supported Program (PI)</li>
    </ul>
    <br>
  </div>
  <script crossorigin="anonymous" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" src="https://code.jquery.com/jquery-3.2.1.slim.min.js"></script>
  <script crossorigin="anonymous" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"></script>
  <script crossorigin="anonymous" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"></script>
</body>
</html>

